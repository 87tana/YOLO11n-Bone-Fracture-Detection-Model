{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/87tana/YOLO11n-Bone-Fracture-Detection-Model/blob/main/basemodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPtiQwanvpsJ"
      },
      "source": [
        "# Setup and Environment Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wXVm1lPvkdJ",
        "outputId": "438d2bd4-ed20-44bb-b808-247aa14369cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Navigate to the project directory\n",
        "%cd '/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HeytaFXLyNHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb6fd94-f5fd-4da7-a428-6e19df9278fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m623.0/623.0 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install MLflow and YOLOv8 dependencies\n",
        "!pip install mlflow ultralytics pyngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mXSMMrUZxOal"
      },
      "outputs": [],
      "source": [
        "# Import YOLOv8 and other necessary modules\n",
        "#import ultralytics\n",
        "#from ultralytics import YOLO\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import mlflow.pyfunc\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from mlflow.tracking import MlflowClient\n",
        "from mlflow.entities import ViewType"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics as ut\n",
        "import mlflow\n",
        "\n",
        "from pyngrok import ngrok\n",
        "#from getpass import getpass\n",
        "import subprocess\n",
        "\n",
        "# Update a setting\n",
        "ut.settings.update({\"mlflow\": True})\n",
        "\n",
        "# Reset settings to default values\n",
        "#ut.settings.reset()"
      ],
      "metadata": {
        "id": "ndh7Cg-dfO5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4bc299-d7e2-4f8d-d3f0-6a13975cc481"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set MLflow tracking directory\n",
        "mlflow_tracking_dir = \"/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/runs/mlflow\"\n",
        "# Set MLflow tracking URI to a folder in Google Drive\n",
        "mlflow.set_tracking_uri(f\"file://{mlflow_tracking_dir}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "lh38n6kXzpWz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a YOLO11model\n",
        "#model = ut.YOLO(\"yolo11n.pt\")  # Choose 'yolo11n.pt' for lightweight training"
      ],
      "metadata": {
        "id": "orP9AmZhlN2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "EVlBf_Ws3xiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set experiment name\n",
        "mlflow.set_experiment(\"Bone_Fracture_Detection\")\n",
        "\n",
        "\n",
        "dataset_path=\"/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset\"\n",
        "\n",
        "\n",
        "params={'experiment_name': 'Fracture_Detection',\n",
        "        'model': 'yolo11n',\n",
        "        'epochs': 5,\n",
        "        'img_size': 640,\n",
        "        'batch_size': 2}\n",
        "\n",
        "\n",
        "# Start an MLflow run\n",
        "\n",
        "with mlflow.start_run(run_name=\"YOLO_Fracture_Detection\") as run:\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"model\", params['model'])\n",
        "    mlflow.log_param(\"epochs\", params['epochs'])\n",
        "    mlflow.log_param(\"img_size\", params['img_size'])\n",
        "    mlflow.log_param(\"batch_size\", params['batch_size'])\n",
        "\n",
        "    # Start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the YOLO model\n",
        "    model = ut.YOLO('yolo11n.pt')  # Load YOLO Nano model\n",
        "    results = model.train(\n",
        "        data=os.path.join(dataset_path, 'data_sample.yaml'),  # Path to your data.yaml file\n",
        "        epochs=params['epochs'],  # Number of epochs\n",
        "        imgsz=params['img_size'],  # Image size\n",
        "        batch=params['batch_size'],  # Batch size\n",
        "        #name=params['experiment_name'],  # Experiment name\n",
        "        project=\"/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Model_Checkpoints\"  # Results directory\n",
        "    )\n",
        "\n",
        "\n",
        "        # Log custom metrics\n",
        "    mlflow.log_metric('mAP', results.maps[0])\n",
        "\n",
        "\n",
        "    # Save model weights and config as artifacts\n",
        "    #mlflow.log_artifact('yolo_weights.h5')\n",
        "    #mlflow.log_artifact('yolo_config.cfg')\n",
        "\n",
        "    # Log training duration\n",
        "    training_duration = time.time() - start_time\n",
        "    mlflow.log_metric(\"training_time\", training_duration)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btUqWxGp0G_9",
        "outputId": "f68a7b73-431b-4da3-ebf1-a3dafca7dfbf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.49 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset/data_sample.yaml, epochs=5, time=None, patience=100, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Model_Checkpoints, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Model_Checkpoints/train11\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 81.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Model_Checkpoints/train11', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset/sample_data/labels.cache... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset/sample_data/labels.cache... 2 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Model_Checkpoints/train11/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/16 10:14:34 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/12/16 10:14:36 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
            "2024/12/16 10:14:36 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/12/16 10:14:36 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/12/16 10:14:36 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(4725970566804e468eb931bce8b97e37) to file:///content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/runs/mlflow\n",
            "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
            "\u001b[34m\u001b[1mMLflow: \u001b[0mWARNING âš ï¸ Failed to initialize: Changing param values is not allowed. Param with key='model' was already logged with value='yolo11n' for run ID='4725970566804e468eb931bce8b97e37'. Attempted logging new value 'yolo11n.pt'.\n",
            "\u001b[34m\u001b[1mMLflow: \u001b[0mWARNING âš ï¸ Not tracking this run\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Model_Checkpoints/train11\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/5         0G       2.47      5.595      2.259          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.44s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00362        0.5    0.00282   0.000564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/5         0G      2.453      6.781      2.223          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.69s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00357        0.5    0.00284    0.00113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/5         0G       3.28      4.887      2.801          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.51s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00357        0.5    0.00284    0.00113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/5         0G      3.458      6.884      2.844          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00334        0.5    0.00276   0.000829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/5         0G      3.306       5.13      2.927          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00334        0.5    0.00276   0.000829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5 epochs completed in 0.008 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Model_Checkpoints/train11/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Model_Checkpoints/train11/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Model_Checkpoints/train11/weights/best.pt...\n",
            "Ultralytics 8.3.49 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          2          2    0.00356        0.5    0.00283   0.000848\n",
            "              Fracture          2          2    0.00356        0.5    0.00283   0.000848\n",
            "Speed: 2.4ms preprocess, 223.4ms inference, 0.0ms loss, 17.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Model_Checkpoints/train11\u001b[0m\n",
            "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to file:///content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/runs/mlflow\n",
            "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run tracking UI in the background\n",
        "subprocess.Popen([\"mlflow\", \"ui\", \"--backend-store-uri\", mlflow_tracking_dir])\n",
        "#get_ipython().system_raw(\"mlflow ui --port 5000 &\") # run tracking UI in the background\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"2qGXY4i9cF4CQHjBRFLtxjuQCTz_Z9PruXmBce21Hfpju7AY\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPHu2DwK3Npx",
        "outputId": "aa976358-6671-444e-9624-ddc4d50b0448"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://0797-35-245-55-86.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation / Test"
      ],
      "metadata": {
        "id": "QlwgKSBC1Nc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize validation settings\n",
        "validation_results = model.val(data=\"/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset/data.yaml\", imgsz=640, batch=16, conf=0.25, iou=0.6, device=\"0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fs3n6Xw1Q7z",
        "outputId": "520ba010-9198-4891-bfc1-fcbc52b572c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.49 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset/valid/labels.cache... 835 images, 5 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 835/835 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:19<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        835       1373      0.047     0.0371     0.0248     0.0168\n",
            "                person        187        202      0.094     0.0743     0.0495     0.0336\n",
            "               bicycle        643       1171          0          0          0          0\n",
            "Speed: 1.2ms preprocess, 5.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference on example images and visualize the results."
      ],
      "metadata": {
        "id": "Xj3BgQ0uo349"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_list = os.listdir('/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset/test/images')"
      ],
      "metadata": {
        "id": "u8QPKzjLoGR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on 'bus.jpg'\n",
        "results = model(os.path.join(\"/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset/test/images/\",image_list[13]))  # results list\n",
        "\n",
        "# Visualize the results\n",
        "for i, r in enumerate(results):\n",
        "    # Plot results image\n",
        "    im_bgr = r.plot()  # BGR-order numpy array\n",
        "    im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
        "\n",
        "    #im_rgb = im_rgb.resize((100, 100))\n",
        "\n",
        "    #im_rgb\n",
        "\n",
        "    # Show results to screen (in supported environments)\n",
        "    r.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "h0P3QzvUltZk",
        "outputId": "67d05241-c3fc-4a92-d63b-78fcb3a4b53c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'image_list' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1b25a830503f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run inference on 'bus.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset/test/images/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# results list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Visualize the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_list' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Ic83wkwbbq"
      },
      "source": [
        "# Model Loading and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXgiWxwCvj8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90264d24-2a32-47d4-8198-22ea257e62e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://21b9-34-16-187-179.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "#NGROK_AUTH_TOKEN = getpass('Enter the ngrok authtoken: ')\n",
        "#ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"2qGXY4i9cF4CQHjBRFLtxjuQCTz_Z9PruXmBce21Hfpju7AY\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "#ngrok.kill()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD7x_IkGwCUx"
      },
      "source": [
        "# Dataset Paths Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Xq01FQTQvkXc"
      },
      "outputs": [],
      "source": [
        "# Define dataset paths\n",
        "dataset_path = '/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset'\n",
        "\n",
        "train_images_dir = os.path.join(dataset_path, 'train/images')\n",
        "train_labels_dir = os.path.join(dataset_path, 'train/labels')\n",
        "\n",
        "validation_images_dir = os.path.join(dataset_path, 'valid/images')\n",
        "validation_labels_dir = os.path.join(dataset_path, 'valid/labels')\n",
        "\n",
        "test_images_dir = os.path.join(dataset_path, 'test/images')\n",
        "test_labels_dir = os.path.join(dataset_path, 'test/labels')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va8o2uK9vj29"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVgqdj/86tc6JAp6dJ5t+5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}